{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c622ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813888a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"E:\\Cyberbullying\\dataset\\raw\\kurrek.2020.slur-corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50cd89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_kurrek_data():\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(r\"E:\\Cyberbullying\\dataset\\raw\\kurrek.2020.slur-corpus.csv\")\n",
    "\n",
    "    # Drop noise\n",
    "    df = df[df['gold_label'] != 'CMP']\n",
    "\n",
    "    # Map labels to binary\n",
    "    label_map = {\n",
    "        'DEG': '1',\n",
    "        'APR': '1',\n",
    "        'NDG': '0',\n",
    "        'HOM': '0'\n",
    "    }\n",
    "    df['binary_label'] = df['gold_label'].map(label_map)\n",
    "\n",
    "    # Optional: Drop rows with NaN (if any remain)\n",
    "    df = df.dropna(subset=['binary_label', 'body'])\n",
    "\n",
    "    return df[['body', 'binary_label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35febe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuck that I dont wanna watch tranny porn.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opie just wanted to have a good time. The same...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuck that faggot Fallon. Fucking sissy boy act...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BbBB...b.b..b.bb but OP's a faggot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who even uses the word tranny except for trans...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>*As an alcoholic who on occasion has one too m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>It's not inaccurate, it's indoctrination of yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>What did you expect?? when they banned /r/nigg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40001</th>\n",
       "      <td>That was hilariously bad. They used the insult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>Reddit in regards to a black woman taking cand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39808 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body binary_label\n",
       "0             Fuck that I dont wanna watch tranny porn.             1\n",
       "1      Opie just wanted to have a good time. The same...            1\n",
       "2      Fuck that faggot Fallon. Fucking sissy boy act...            1\n",
       "3                     BbBB...b.b..b.bb but OP's a faggot            1\n",
       "4      Who even uses the word tranny except for trans...            0\n",
       "...                                                  ...          ...\n",
       "39998  *As an alcoholic who on occasion has one too m...            1\n",
       "39999  It's not inaccurate, it's indoctrination of yo...            1\n",
       "40000  What did you expect?? when they banned /r/nigg...            0\n",
       "40001  That was hilariously bad. They used the insult...            0\n",
       "40002  Reddit in regards to a black woman taking cand...            0\n",
       "\n",
       "[39808 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kurrek_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6f6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXIC_PATH= r\"E:\\Cyberbullying\\dataset\\new\\OFF_HATE_TOXIC_DATASET.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db25fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_toxic_dataset(path=TOXIC_PATH):\n",
    "    # Load dataset\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    # OFF_HATEFUL_TOXIC: offensive, hateful, or toxic content\n",
    "    # NOT_OFF_HATEFUL_TOXIC: non-offensive, non-hateful, or non-toxic content\n",
    "    df['label'] = df['label'].map({\n",
    "        'NOT_OFF_HATEFUL_TOXIC': 0,\n",
    "        'OFF_HATEFUL_TOXIC': 1})\n",
    "    df = df.dropna(subset=['text', 'label'])\n",
    "    df = df.drop_duplicates(subset=['text', 'label'], keep='first')\n",
    "    return df[['text', 'label']]\n",
    "toxic_df=load_toxic_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d638098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<string>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19560\\3887051702.py:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  df_balanced.to_csv(f\"E:\\Cyberbullying\\dataset\\preprocessed\\{name}.csv\", index=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19560\\3887051702.py:20: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  df_balanced.to_csv(f\"E:\\Cyberbullying\\dataset\\preprocessed\\{name}.csv\", index=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_dataset(toxic_df,name):\n",
    "    df_majority = toxic_df[toxic_df['label'] == 0]\n",
    "    df_minority = toxic_df[toxic_df['label'] == 1]\n",
    "\n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = resample(df_majority,\n",
    "                                    replace=False,     # without replacement\n",
    "                                    n_samples=len(df_minority),  # match minority count\n",
    "                                    random_state=42)\n",
    "\n",
    "    # Combine balanced data\n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    # Shuffle\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(df_balanced['label'].value_counts())\n",
    "    df_balanced.to_csv(f\"E:\\Cyberbullying\\dataset\\preprocessed\\{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59b4673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    19413\n",
      "1    19413\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balance_dataset(toxic_df,'OFF_HATE_TOXIC_DATASET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b1ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHS_PATH = r\"E:\\Cyberbullying\\dataset\\new\\gender-hate-speech-train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841c8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ghs_dataset(path=GHS_PATH):\n",
    "    # Load dataset\n",
    "    ghs_df = pd.read_csv(path)\n",
    "\n",
    "    ghs_df['Label'] = ghs_df['Label'].apply(lambda x: 0 if x ==0 else 1) #\n",
    "\n",
    "\n",
    "    # Optional: Drop rows with NaN (if any remain)\n",
    "    ghs_df = ghs_df.dropna(subset=['Text', 'Label'])\n",
    "    ghs_df = ghs_df.drop_duplicates(subset=['Text', 'Label'], keep='first')\n",
    "    ghs_df.rename(columns={'Label': 'label'}, inplace=True) # Align column name\n",
    "    ghs_df.rename(columns={'Text': 'text'}, inplace=True) # Align column name\n",
    "\n",
    "    return ghs_df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c456c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs_df = load_ghs_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95ddd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    7011\n",
      "1    7011\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balance_dataset(ghs_df,'GHS_DATASET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57890fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_HATE_PATH=r\"E:\\Cyberbullying\\dataset\\new\\hate-multi.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4566c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_hate_dataset(path=MULTI_HATE_PATH):\n",
    "    # Load dataset\n",
    "    multi_df = pd.read_parquet(path)\n",
    "\n",
    "\n",
    "    \n",
    "    multi_df = multi_df.dropna(subset=['text', 'label'])\n",
    "    multi_df = multi_df.drop_duplicates(subset=['text', 'label'], keep='first')\n",
    "    \n",
    "    return multi_df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0544dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df=load_multi_hate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92fb317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    44826\n",
       "1    17515\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b53b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    17515\n",
      "1    17515\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balance_dataset(multi_df,'MULTI_HATE_DATASET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d52fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Combine them\u001b[39;00m\n\u001b[32m      9\u001b[39m merged_df = pd.concat([df1, df2, df3], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m != \u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Remove duplicate rows (optional but common)\u001b[39;00m\n\u001b[32m     12\u001b[39m merged_df = merged_df.drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'text'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df1 = pd.read_csv(r'E:\\Cyberbullying\\dataset\\preprocessed\\GHS_DATASET.csv', names=['text', 'label'], header=None)\n",
    "df2 = pd.read_csv(r\"E:\\Cyberbullying\\dataset\\preprocessed\\MULTI_HATE_DATASET.csv\", names=['text', 'label'], header=None)\n",
    "df3 = pd.read_csv(r\"E:\\Cyberbullying\\dataset\\preprocessed\\OFF_HATE_TOXIC_DATASET.csv\", names=['text', 'label'], header=None)\n",
    "\n",
    "# Combine them\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Remove duplicate rows (optional but common)\n",
    "merged_df = merged_df.drop_duplicates(subset=['text', 'label']).reset_index(drop=True)\n",
    "\n",
    "# Check result\n",
    "print(merged_df.shape)\n",
    "print(merged_df['label'].value_counts())\n",
    "merged_df.to_csv(r\"E:\\Cyberbullying\\dataset\\preprocessed\\merged_dataset.csv\", index=False)\n",
    "print(\"Merged dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e571acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like this if you wanna kiss princess bubblegum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forbidding women from winning because you don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dreamt there was a new lesbian movie on Netfli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no interest in speaking with anyone fal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87873</th>\n",
       "      <td>Ever hear him praise General Lee ?   Has he ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87874</th>\n",
       "      <td>@user @user Thank you. Not all men are bad. In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87875</th>\n",
       "      <td>I do not call him IslamaObama for nothing he i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87876</th>\n",
       "      <td>ðŸ’œðŸ’“ðŸ’œÂ Happy Wednesday My Dear #GabFam Friends! ðŸ’œ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87877</th>\n",
       "      <td>A N S I E D A D E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87878 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                                   text  label\n",
       "1      like this if you wanna kiss princess bubblegum...      0\n",
       "2      Forbidding women from winning because you don'...      0\n",
       "3      Dreamt there was a new lesbian movie on Netfli...      0\n",
       "4      I have no interest in speaking with anyone fal...      1\n",
       "...                                                  ...    ...\n",
       "87873  Ever hear him praise General Lee ?   Has he ev...      0\n",
       "87874  @user @user Thank you. Not all men are bad. In...      0\n",
       "87875  I do not call him IslamaObama for nothing he i...      1\n",
       "87876  ðŸ’œðŸ’“ðŸ’œÂ Happy Wednesday My Dear #GabFam Friends! ðŸ’œ...      0\n",
       "87877                                  A N S I E D A D E      0\n",
       "\n",
       "[87878 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "OMG_PATH= r\"E:\\Cyberbullying\\dataset\\preprocessed\\OMG.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4646bdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like this if you wanna kiss princess bubblegum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forbidding women from winning because you don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dreamt there was a new lesbian movie on Netfli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have no interest in speaking with anyone fal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trevor has some sort of gender and its not cis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87872</th>\n",
       "      <td>Ever hear him praise General Lee ?   Has he ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87873</th>\n",
       "      <td>@user @user Thank you. Not all men are bad. In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87874</th>\n",
       "      <td>I do not call him IslamaObama for nothing he i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87875</th>\n",
       "      <td>ðŸ’œðŸ’“ðŸ’œÂ Happy Wednesday My Dear #GabFam Friends! ðŸ’œ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87876</th>\n",
       "      <td>A N S I E D A D E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87877 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      like this if you wanna kiss princess bubblegum...      0\n",
       "1      Forbidding women from winning because you don'...      0\n",
       "2      Dreamt there was a new lesbian movie on Netfli...      0\n",
       "3      I have no interest in speaking with anyone fal...      1\n",
       "4      trevor has some sort of gender and its not cis...      0\n",
       "...                                                  ...    ...\n",
       "87872  Ever hear him praise General Lee ?   Has he ev...      0\n",
       "87873  @user @user Thank you. Not all men are bad. In...      0\n",
       "87874  I do not call him IslamaObama for nothing he i...      1\n",
       "87875  ðŸ’œðŸ’“ðŸ’œÂ Happy Wednesday My Dear #GabFam Friends! ðŸ’œ...      0\n",
       "87876                                  A N S I E D A D E      0\n",
       "\n",
       "[87877 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_omg_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f7594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
