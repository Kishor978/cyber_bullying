{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0417cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Cyberbullying\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np  \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13edeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "HATEMOJI_VALIDATION_PATH = r\"E:\\Cyberbullying\\dataset\\raw\\HatemojiBuild\\train.csv\"\n",
    "EMOTION_FUSION_MODEL_OUTPUT_DIR = './results/emotion_fusion_model'\n",
    "RANDOM_STATE= 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad84c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hatemoji_validation_dataset(path=HATEMOJI_VALIDATION_PATH):\n",
    "    \"\"\"Loads the Hatemoji validation dataset.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['text', 'label_gold']].dropna()\n",
    "    \n",
    "    df.rename(columns={'label_gold': 'label'}, inplace=True) # Align column name\n",
    "    \n",
    "    print(f\"Loaded Hatemoji validation dataset from {path}\")\n",
    "    print(\"Hatemoji Label distribution:\\n\", df['label'].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50acef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import emoji\n",
    "from tqdm.auto import tqdm # Use tqdm.auto for notebook/script compatibility\n",
    "\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "emotion_pipeline = None\n",
    "\n",
    "\n",
    "def initialize_emotion_analyzer():\n",
    "    global emotion_pipeline\n",
    "    if emotion_pipeline is None:\n",
    "        model_name = \"j-hartmann/emotion-english-distilroberta-base\" #\n",
    "        try:\n",
    "            # You might need to ensure model files are cached or downloaded before this step\n",
    "            # cached_file(\"j-hartmann/emotion-english-distilroberta-base\", \"config.json\", force_download=True)\n",
    "            emotion_pipeline = pipeline( #\n",
    "                \"text-classification\", #\n",
    "                model=model_name, #\n",
    "                return_all_scores=True, #\n",
    "                framework=\"pt\" #\n",
    "            )\n",
    "            print(\"‚úÖ Emotion analysis pipeline loaded successfully!\")\n",
    "        except Exception as e: #\n",
    "            print(f\"‚ùå Failed to load emotion model: {e}\") #\n",
    "            emotion_pipeline = None\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ordered emotion labels from the model\n",
    "EMOTION_LABELS = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "def extract_features(text, max_length=128):\n",
    "    \"\"\"Extracts VADER sentiment and emotion vector (7D) from text safely.\"\"\"\n",
    "    initialize_emotion_analyzer()\n",
    "\n",
    "    try:\n",
    "        text = limit_emoji_repeats(text)\n",
    "        text_with_emojis = emoji.demojize(text)\n",
    "\n",
    "        # VADER sentiment\n",
    "        vader_score = vader_analyzer.polarity_scores(text_with_emojis)['compound']\n",
    "    except Exception as e:\n",
    "        print(f\"[‚ùå VADER failed] {text[:80]}... | {e}\")\n",
    "        vader_score = 0.0\n",
    "\n",
    "    emotion_vector = [0.0] * len(EMOTION_LABELS)\n",
    "\n",
    "    if emotion_pipeline:\n",
    "        try:\n",
    "            # Truncate long text using tokenizer from pipeline\n",
    "            tokenizer = emotion_pipeline.tokenizer\n",
    "            if tokenizer:\n",
    "                encoded = tokenizer(text_with_emojis, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "                decoded = tokenizer.decode(encoded[\"input_ids\"][0], skip_special_tokens=True)\n",
    "            else:\n",
    "                decoded = text_with_emojis\n",
    "\n",
    "            emotions = emotion_pipeline(decoded)\n",
    "            # print(f\"[DEBUG] text: {decoded[:80]}...\\n[DEBUG] pipeline output: {emotions}\\n\")\n",
    "\n",
    "            if not emotions or not isinstance(emotions[0], list):\n",
    "                raise ValueError(\"Empty or invalid emotion output.\")\n",
    "\n",
    "            # Convert list of dicts to dict for safe access\n",
    "            emotion_scores = {e['label']: e['score'] for e in emotions[0]}\n",
    "\n",
    "            # Build vector in fixed label order\n",
    "            emotion_vector = [emotion_scores.get(label, 0.0) for label in EMOTION_LABELS]\n",
    "\n",
    "            # Sanity check\n",
    "            if len(emotion_vector) != len(EMOTION_LABELS) or np.any(np.isnan(emotion_vector)) or np.any(np.isinf(emotion_vector)):\n",
    "                raise ValueError(\"Invalid emotion vector content.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[‚ö†Ô∏è Emotion extraction failed] {text[:80]}... | Reason: {e}\")\n",
    "            emotion_vector = [0.0] * len(EMOTION_LABELS)\n",
    "\n",
    "    return vader_score, emotion_vector\n",
    "\n",
    "def process_texts_for_emotion_features(df, text_column='text'):\n",
    "    \"\"\"Applies emotion and sentiment extraction to each row safely.\"\"\"\n",
    "    emoji_scores = []\n",
    "    emotion_vectors = []\n",
    "\n",
    "    print(\"üîç Extracting emotion and sentiment features...\")\n",
    "    for t in tqdm(df[text_column], desc=\"Extracting Emotion Features\"):\n",
    "        score, vector = extract_features(t)\n",
    "        emoji_scores.append(score)\n",
    "        emotion_vectors.append(vector)\n",
    "\n",
    "    df['emoji_score'] = emoji_scores\n",
    "    df['emotion_vector'] = emotion_vectors\n",
    "\n",
    "    # --- Determine expected emotion vector length dynamically ---\n",
    "    valid_lengths = df['emotion_vector'].apply(lambda x: isinstance(x, list)).sum()\n",
    "    vector_lengths = df['emotion_vector'].apply(lambda x: len(x) if isinstance(x, list) else -1)\n",
    "    most_common_length = vector_lengths[vector_lengths != -1].mode().iloc[0] if not vector_lengths.empty else 0\n",
    "\n",
    "    print(f\"‚úÖ Detected most common emotion vector length: {most_common_length}\")\n",
    "\n",
    "    # --- Clean data ---\n",
    "    # Keep only rows with valid emoji score\n",
    "    df = df[df['emoji_score'].apply(lambda x: isinstance(x, (int, float)) and not np.isnan(x))]\n",
    "\n",
    "    # Keep only rows with valid-length, finite emotion vectors\n",
    "    df = df[df['emotion_vector'].apply(\n",
    "        lambda x: isinstance(x, list)\n",
    "        and len(x) == most_common_length\n",
    "        and all(np.isfinite(xi) for xi in x)\n",
    "    )]\n",
    "\n",
    "    print(f\"üßπ After filtering: {df.shape[0]} valid rows retained.\")\n",
    "    return df\n",
    "\n",
    "import re\n",
    "\n",
    "def limit_emoji_repeats(text, max_repeat=5):\n",
    "    emoji_pattern = r'(([\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF])+)\\2{' + str(max_repeat) + ',}'\n",
    "    return re.sub(emoji_pattern, r'\\1'*max_repeat, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8ee42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset class\n",
    "class CyberbullyingFusionDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, emoji_scores, emotion_vectors, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.emoji_scores = emoji_scores\n",
    "        self.emotion_vectors = emotion_vectors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Ensure labels are float for BCELoss\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'emoji_score': torch.tensor(self.emoji_scores[idx], dtype=torch.float),\n",
    "            'emotion_vector': torch.tensor(self.emotion_vectors[idx], dtype=torch.float),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float) # Changed from torch.long to torch.float\n",
    "        }\n",
    "\n",
    "# Define the fusion model\n",
    "class BERTEmojiEmotionClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', emotion_dim=768, dropout_prob=0.1): # Default emotion_dim for now\n",
    "        super(BERTEmojiEmotionClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Assuming BERT's last hidden state is 768\n",
    "        bert_output_dim = self.bert.config.hidden_size\n",
    "        \n",
    "        # Linear layer for emoji score\n",
    "        self.emoji_fc = nn.Linear(1, 64) # Simple FC layer for emoji score\n",
    "        \n",
    "        # Linear layer for emotion vector (if it's not already 768 or compatible)\n",
    "        # Adjust input dimension based on the actual size of your emotion vector\n",
    "        self.emotion_fc = nn.Linear(emotion_dim, 128) # Map emotion_dim to a compatible size\n",
    "\n",
    "        # Fusion layer: BERT output + Emoji FC output + Emotion FC output\n",
    "        # Adjust the input dimension of the fusion_fc based on actual concatenated sizes\n",
    "        # For simplicity, let's assume we map all to 256 for concatenation example\n",
    "        # (bert_output_dim + 64 + 128) -> This is the input to fusion_fc\n",
    "        self.fusion_fc = nn.Linear(bert_output_dim + 64 + 128, 256)\n",
    "        \n",
    "        self.classifier = nn.Linear(256, 1) # Output for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, emoji_score, emotion_vector):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :] # Use CLS token output\n",
    "        \n",
    "        emoji_features = self.emoji_fc(emoji_score.unsqueeze(1)) # Add a dimension for the single score\n",
    "        \n",
    "        # Ensure emotion_vector has the correct shape for the linear layer\n",
    "        # If emotion_vector is already (batch_size, emotion_dim), no unsqueeze needed\n",
    "        emotion_features = self.emotion_fc(emotion_vector)\n",
    "        \n",
    "        # Concatenate features\n",
    "        # Ensure all features are 2D (batch_size, feature_dim) before concatenation\n",
    "        combined_features = torch.cat((bert_output, emoji_features, emotion_features), dim=1)\n",
    "        \n",
    "        combined_features = self.dropout(combined_features)\n",
    "        fusion_output = self.fusion_fc(combined_features)\n",
    "        logits = self.classifier(fusion_output)\n",
    "        return self.sigmoid(logits).squeeze(1) # Squeeze to make it (batch_size,)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_fusion_model_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        emoji_score = batch['emoji_score'].to(device)\n",
    "        emotion_vector = batch['emotion_vector'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, emoji_score, emotion_vector)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_fusion_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            emoji_score = batch['emoji_score'].to(device)\n",
    "            emotion_vector = batch['emotion_vector'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, emoji_score, emotion_vector)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    # Ensure all_labels and all_predictions are lists or numpy arrays before conversion\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "\n",
    "    # Convert to integer type for sklearn metrics if they were originally floats 0.0/1.0\n",
    "    all_labels_int = all_labels_np.astype(int)\n",
    "    all_predictions_int = all_predictions_np.astype(int)\n",
    "\n",
    "    return avg_loss, all_predictions_int, all_labels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb76920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def print_classification_metrics(y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Prints accuracy, precision, recall, F1-score, and the full classification report.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred) #\n",
    "    precision = precision_score(y_true, y_pred) #\n",
    "    recall = recall_score(y_true, y_pred) #\n",
    "    f1 = f1_score(y_true, y_pred) #\n",
    "\n",
    "    print(f\"\\n--- Metrics for {dataset_name} ---\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\") #\n",
    "    print(f\"Precision: {precision:.4f}\") #\n",
    "    print(f\"Recall:    {recall:.4f}\") #\n",
    "    print(f\"F1-Score:  {f1:.4f}\") #\n",
    "    print(f\"\\nClassification Report of {dataset_name}:\\n\", classification_report(y_true, y_pred)) #\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\", save_path=None):\n",
    "    \"\"\"Plots and optionally saves a confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred) #\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', #\n",
    "                xticklabels=['Non-bullying', 'Bullying'], #\n",
    "                yticklabels=['Non-bullying', 'Bullying']) #\n",
    "    plt.xlabel('Predicted') #\n",
    "    plt.ylabel('Actual') #\n",
    "    plt.title(title) #\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved confusion matrix to {save_path}\")\n",
    "    plt.show() #\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies, title_prefix=\"\", save_path=None): # From bilstm.ipynb\n",
    "    \"\"\"Plots training and validation loss/accuracy over epochs.\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1) #\n",
    "\n",
    "    plt.figure(figsize=(12, 5)) #\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1) #\n",
    "    plt.plot(epochs, train_losses, label='Train Loss') #\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss') #\n",
    "    plt.title(f'{title_prefix} Loss per Epoch') #\n",
    "    plt.xlabel('Epoch') #\n",
    "    plt.ylabel('Loss') #\n",
    "    plt.legend() #\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2) #\n",
    "    plt.plot(epochs, train_accuracies, label='Train Accuracy') #\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy') #\n",
    "    plt.title(f'{title_prefix} Accuracy per Epoch') #\n",
    "    plt.xlabel('Epoch') #\n",
    "    plt.ylabel('Accuracy') #\n",
    "    plt.legend() #\n",
    "\n",
    "    plt.tight_layout() #\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved training history plot to {save_path}\")\n",
    "    plt.show() #\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc6c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_emotion_fusion_model_experiment():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"                Running Emotion Fusion Model Experiment               \")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    df_fusion = load_hatemoji_validation_dataset()\n",
    "    print(f\"üîπ Loaded dataset: {df_fusion.shape[0]} rows\")\n",
    "\n",
    "    df_fusion = process_texts_for_emotion_features(df_fusion)\n",
    "    print(f\"üîπ After emotion feature extraction: {df_fusion.shape}\")\n",
    "\n",
    "    # Debug: check issues with emotion vectors\n",
    "    zero_vectors = df_fusion['emotion_vector'].apply(lambda x: isinstance(x, list) and np.all(np.array(x) == 0.0)).sum()\n",
    "    invalid_lengths = df_fusion['emotion_vector'].apply(lambda x: not isinstance(x, list) or len(x) != 7).sum()\n",
    "    print(f\"‚ö†Ô∏è  Rows with all-zero emotion vectors: {zero_vectors}\")\n",
    "    print(f\"‚ùå Rows with invalid-length vectors: {invalid_lengths}\")\n",
    "    print(f\"‚úÖ Rows with valid non-zero vectors: {df_fusion.shape[0] - zero_vectors - invalid_lengths}\")\n",
    "\n",
    "    # Filter only valid rows\n",
    "    df_fusion = df_fusion[df_fusion['text'].notnull() & df_fusion['text'].str.strip().astype(bool)]\n",
    "    df_fusion = df_fusion[df_fusion['emoji_score'].notnull()]\n",
    "    df_fusion = df_fusion[df_fusion['emotion_vector'].apply(lambda x: isinstance(x, list) and len(x) == 7)]\n",
    "    print(f\"üßπ After cleaning: {df_fusion.shape[0]} rows remaining\")\n",
    "\n",
    "    if df_fusion.empty:\n",
    "        print(\"‚ùå ERROR: All rows dropped during cleaning. Check emotion model or data quality.\")\n",
    "        return\n",
    "\n",
    "    # Optional: Remove zero vectors if needed\n",
    "    # df_fusion = df_fusion[df_fusion['emotion_vector'].apply(lambda x: sum(x) > 0.0)]\n",
    "\n",
    "    # Tokenizer sanity check\n",
    "    print(\"\\n‚úÖ Tokenizer input check:\")\n",
    "    print(f\"Number of texts: {len(df_fusion['text'])}\")\n",
    "    print(f\"Example text: {df_fusion['text'].iloc[0]}\")\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    encodings = tokenizer(list(df_fusion['text']), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    input_ids = encodings['input_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        df_fusion, test_size=TEST_SIZE, stratify=df_fusion['label'], random_state=RANDOM_STATE)\n",
    "\n",
    "    # Create Dataset and DataLoader instances\n",
    "    train_dataset = CyberbullyingFusionDataset(\n",
    "        input_ids=tokenizer(list(train_data['text']), truncation=True, padding=True, max_length=128)['input_ids'],\n",
    "        attention_masks=tokenizer(list(train_data['text']), truncation=True, padding=True, max_length=128)['attention_mask'],\n",
    "        emoji_scores=list(train_data['emoji_score']),\n",
    "        emotion_vectors=list(train_data['emotion_vector']),\n",
    "        labels=list(train_data['label'])\n",
    "    )\n",
    "\n",
    "    test_dataset = CyberbullyingFusionDataset(\n",
    "        input_ids=tokenizer(list(test_data['text']), truncation=True, padding=True, max_length=128)['input_ids'],\n",
    "        attention_masks=tokenizer(list(test_data['text']), truncation=True, padding=True, max_length=128)['attention_mask'],\n",
    "        emoji_scores=list(test_data['emoji_score']),\n",
    "        emotion_vectors=list(test_data['emotion_vector']),\n",
    "        labels=list(test_data['label'])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    model = BERTEmojiEmotionClassifier(emotion_dim=7).to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    print(\"\\n--- Training Emotion Fusion Model ---\")\n",
    "    for epoch in range(1, 6):\n",
    "        train_loss, train_acc = train_fusion_model_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, y_pred, y_true = evaluate_fusion_model(model, test_loader, criterion, device)\n",
    "        acc_val = accuracy_score(y_true, y_pred)\n",
    "        prec_val = precision_score(y_true, y_pred)\n",
    "        rec_val = recall_score(y_true, y_pred)\n",
    "        f1_val = f1_score(y_true, y_pred)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(acc_val)\n",
    "\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {acc_val:.4f}, Precision: {prec_val:.4f}, Recall: {rec_val:.4f}, F1: {f1_val:.4f}\")\n",
    "\n",
    "    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies,\n",
    "                          \"Emotion Fusion Model\", save_path=\"./results/emotion_fusion_training_history.png\")\n",
    "\n",
    "    print(\"\\n--- Evaluating Emotion Fusion Model ---\")\n",
    "    _, y_pred_fusion, y_true_fusion = evaluate_fusion_model(model, test_loader, criterion, device)\n",
    "    print_classification_metrics(y_true_fusion, y_pred_fusion, \"Emotion Fusion Model\")\n",
    "    plot_confusion_matrix(y_true_fusion, y_pred_fusion, \"Confusion Matrix - Proposed Model\",\n",
    "                          save_path=\"./results/emotion_fusion_confusion_matrix.png\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), EMOTION_FUSION_MODEL_OUTPUT_DIR + \"/emotion_fusion_model.pth\")\n",
    "    print(f\"‚úÖ Emotion Fusion model saved to {EMOTION_FUSION_MODEL_OUTPUT_DIR}/emotion_fusion_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e062524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                Running Emotion Fusion Model Experiment               \n",
      "================================================================================\n",
      "\n",
      "Loaded Hatemoji validation dataset from E:\\Cyberbullying\\dataset\\raw\\HatemojiBuild\\train.csv\n",
      "Hatemoji Label distribution:\n",
      " label\n",
      "1    2387\n",
      "0    2341\n",
      "Name: count, dtype: int64\n",
      "üîπ Loaded dataset: 4728 rows\n",
      "üîç Extracting emotion and sentiment features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Emotion Features:  24%|‚ñà‚ñà‚ñç       | 1154/4728 [01:00<03:46, 15.76it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "Extracting Emotion Features:  24%|‚ñà‚ñà‚ñç       | 1156/4728 [01:01<03:35, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion analysis failed: index out of range in self\n",
      "Emotion analysis failed: The expanded size of the tensor (524) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 524].  Tensor sizes: [1, 514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Emotion Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4728/4728 [04:52<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected most common emotion vector length: 7\n",
      "üßπ After filtering: 4726 valid rows retained.\n",
      "üîπ After emotion feature extraction: (4726, 4)\n",
      "‚ö†Ô∏è  Rows with all-zero emotion vectors: 0\n",
      "‚ùå Rows with invalid-length vectors: 0\n",
      "‚úÖ Rows with valid non-zero vectors: 4726\n",
      "üßπ After cleaning: 4726 rows remaining\n",
      "\n",
      "‚úÖ Tokenizer input check:\n",
      "Number of texts: 4726\n",
      "Example text: I would love to üî™ some üë≥üèæ\n",
      "\n",
      "--- Training Emotion Fusion Model ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_emotion_fusion_model_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mrun_emotion_fusion_model_experiment\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Training Emotion Fusion Model ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     train_loss, train_acc = \u001b[43mtrain_fusion_model_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     val_loss, y_pred, y_true = evaluate_fusion_model(model, test_loader, criterion, device)\n\u001b[32m     77\u001b[39m     acc_val = accuracy_score(y_true, y_pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mtrain_fusion_model_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     89\u001b[39m outputs = model(input_ids, attention_mask, emoji_score, emotion_vector)\n\u001b[32m     90\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m optimizer.step()\n\u001b[32m     94\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Cyberbullying\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_emotion_fusion_model_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
