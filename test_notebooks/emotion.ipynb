{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(r\"E:\\Cyberbullying\\dataset\\HatemojiBuild\\validation.csv\")\n",
    "\n",
    "# Filter only needed columns\n",
    "df = df[['text', 'label_gold']].dropna()\n",
    "\n",
    "# Binary labels\n",
    "df['label'] = df['label_gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import cached_file\n",
    "cached_file(\"j-hartmann/emotion-english-distilroberta-base\", \"config.json\", force_download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Model loading failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff44761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import emoji\n",
    "\n",
    "# Load tools\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Optional: Use explicit model and tokenizer loading for more control\n",
    "try:\n",
    "    emotion_analyzer = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "        return_all_scores=True,\n",
    "        framework=\"pt\"  # or \"tf\" if you use TensorFlow\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Failed to load emotion model:\", e)\n",
    "    emotion_analyzer = None\n",
    "\n",
    "def extract_features(text):\n",
    "    # Step 1: Convert emojis to text\n",
    "    text_with_emojis = emoji.demojize(text)\n",
    "\n",
    "    # Step 2: VADER sentiment score\n",
    "    vader_score = vader.polarity_scores(text_with_emojis)['compound']\n",
    "\n",
    "    # Step 3: Emotion analysis\n",
    "    emotion_vector = []\n",
    "    if emotion_analyzer:\n",
    "        try:\n",
    "            emotions = emotion_analyzer(text_with_emojis)\n",
    "            emotion_vector = [e['score'] for e in emotions[0]]\n",
    "        except Exception as e:\n",
    "            print(\"Emotion analysis failed:\", e)\n",
    "            emotion_vector = [0.0] * 6  # Assuming 6 emotion classes as placeholder\n",
    "\n",
    "    return vader_score, emotion_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "emoji_scores = []\n",
    "emotion_vectors = []\n",
    "\n",
    "for t in tqdm(df['text']):\n",
    "    s, e = extract_features(t)\n",
    "    emoji_scores.append(s)\n",
    "    emotion_vectors.append(e)\n",
    "\n",
    "df['emoji_score'] = emoji_scores\n",
    "df['emotion_vector'] = emotion_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text', 'emoji_score', 'emotion_vector'])  # just in case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "encodings = tokenizer(\n",
    "    list(df['text']), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "input_ids = encodings['input_ids']\n",
    "attention_mask = encodings['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CyberbullyingFusionDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, emoji_scores, emotion_vectors, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.emoji_scores = emoji_scores\n",
    "        self.emotion_vectors = emotion_vectors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'emoji_score': torch.tensor(self.emoji_scores[idx], dtype=torch.float32),\n",
    "            'emotion_vector': torch.tensor(self.emotion_vectors[idx], dtype=torch.float32),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "train_dataset = CyberbullyingFusionDataset(\n",
    "    input_ids=tokenizer(list(train_data['text']), truncation=True, padding=True, max_length=128)['input_ids'],\n",
    "    attention_masks=tokenizer(list(train_data['text']), truncation=True, padding=True, max_length=128)['attention_mask'],\n",
    "    emoji_scores=list(train_data['emoji_score']),\n",
    "    emotion_vectors=list(train_data['emotion_vector']),\n",
    "    labels=list(train_data['label'])\n",
    ")\n",
    "\n",
    "test_dataset = CyberbullyingFusionDataset(\n",
    "    input_ids=tokenizer(list(test_data['text']), truncation=True, padding=True, max_length=128)['input_ids'],\n",
    "    attention_masks=tokenizer(list(test_data['text']), truncation=True, padding=True, max_length=128)['attention_mask'],\n",
    "    emoji_scores=list(test_data['emoji_score']),\n",
    "    emotion_vectors=list(test_data['emotion_vector']),\n",
    "    labels=list(test_data['label'])\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BERTEmojiEmotionClassifier(nn.Module):\n",
    "    def __init__(self, emotion_dim=6, hidden_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        # Optional: project emotion and emoji features if needed\n",
    "        self.emoji_proj = nn.Linear(1, 8)\n",
    "        self.emotion_proj = nn.Linear(emotion_dim, 32)\n",
    "\n",
    "        # Fusion + classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 8 + 32, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, emoji_score, emotion_vector):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "\n",
    "        emoji_feat = self.emoji_proj(emoji_score.unsqueeze(1))  # shape: [B, 8]\n",
    "        emotion_feat = self.emotion_proj(emotion_vector)        # shape: [B, 32]\n",
    "\n",
    "        combined = torch.cat((cls_embedding, emoji_feat, emotion_feat), dim=1)\n",
    "        out = self.classifier(combined)\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTEmojiEmotionClassifier(emotion_dim=len(train_data['emotion_vector'].iloc[0])).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        emoji_score = batch['emoji_score'].to(device)\n",
    "        emotion_vector = batch['emotion_vector'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, emoji_score, emotion_vector)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            emoji_score = batch['emoji_score'].to(device)\n",
    "            emotion_vector = batch['emotion_vector'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, emoji_score, emotion_vector)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (outputs >= 0.5).long().cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    return acc, prec, rec, f1, total_loss / len(loader), all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    acc, prec, rec, f1, val_loss, _, _ = evaluate_model(model, test_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Val Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Acc')\n",
    "plt.plot(epochs, val_accuracies, label='Val Acc')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# After final evaluation\n",
    "acc, prec, rec, f1, _, y_pred, y_true = evaluate_model(model, test_loader)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Non-Bullying', 'Bullying'],\n",
    "            yticklabels=['Non-Bullying', 'Bullying'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Proposed Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f807c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
